---
# yamllint disable-line rule:line-length
# yaml-language-server: $schema=https://github.com/datreeio/CRDs-catalog/raw/main/monitoring.coreos.com/prometheusrule_v1.json
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: persistent-volumes
  namespace: prometheus-metrics
  labels:
    alertmanager: metrics
spec:
  groups:
    - name: persistent-volume-claims
      rules:
        - alert: PersistentVolumeClaimUsageWarning
          expr: |2-
              kubelet_volume_stats_available_bytes{
                job="kubelet",
                metrics_path="/metrics"
              }
            / kubelet_volume_stats_capacity_bytes{
                job="kubelet",
                metrics_path="/metrics"
              }
            < 0.20
          for: 1m
          annotations:
            title: >-
              `PersistentVolumeClaim` is Filling Up
            summary: >-
              One or more `PersistentVolumeClaims` on the `{{$externalLabels.cluster}}` Cluster is
              reporting as having *less than 20% of its total available capacity free*, which is
              below the *warning* limit.
            description: >-
              `{{$labels.namespace}}/{{$labels.persistentvolumeclaim}}`
              (*{{$value|humanizePercentage}}*)
            dashboard: https://grafana.${cluster_domain}/
            runbook: https://d.n3t.uk/runbooks/
          labels:
            ignore: outside-non-work-hours
            # severity can be info, errors, warning, critical
            severity: warning
            # slack is the name of the channel to send messages to
            slack: kub3-${cluster}-alerts-infra
            # pagerduty can either be send or ignore for Alerts
            pagerduty: send
            # incidentio can either create incidents, send Alerts, or ignore
            incidentio: send
            # team sets the Team and Escalation Path to use for the incident
            team: platform

        - alert: PersistentVolumeClaimUsageCritical
          expr: |2-
              kubelet_volume_stats_available_bytes{
                job="kubelet",
                metrics_path="/metrics"
              }
            / kubelet_volume_stats_capacity_bytes{
                job="kubelet",
                metrics_path="/metrics"
              }
            < 0.05
          for: 1m
          annotations:
            title: >-
              `PersistentVolumeClaim` is Almost Full
            summary: >-
              One or more `PersistentVolumeClaims` on the `{{$externalLabels.cluster}}` Cluster is
              reporting as having less *than 5% of its total available capacity free*, which is
              below the *critical* limit.
            description: >-
              `{{$labels.namespace}}/{{$labels.persistentvolumeclaim}}`
              (*{{$value|humanizePercentage}}*)
            dashboard: https://grafana.${cluster_domain}/
            runbook: https://d.n3t.uk/runbooks/
          labels:
            ignore: outside-extended-hours
            severity: critical
            slack: kub3-${cluster}-alerts-infra
            pagerduty: send
            incidentio: create
            team: platform

        - alert: PersistentVolumeClaimCapacityWarning
          expr: |-
            (
              (
                kubelet_volume_stats_available_bytes{
                  job="kubelet",
                  metrics_path="/metrics"
                }
              / kubelet_volume_stats_capacity_bytes{
                  job="kubelet",
                  metrics_path="/metrics"
                }
              ) <= 0.3
              and
              predict_linear(
                kubelet_volume_stats_available_bytes{
                  job="kubelet",
                  metrics_path="/metrics"
                }[6h],
                (7 * 24 * 60 * 60)
              ) <= 0
            )
          for: 30m
          annotations:
            title: >-
              `PersistentVolumeClaim` Nearing Capacity within 7d
            summary: >-
              One or more `PersistentVolumeClaims` on the `{{$externalLabels.cluster}}` Cluster is
              reporting as having *less than 30% of its total available capacity free*, and, based
              on current rates of storage, *will fill within the next seven days*, which is below
              the *warning* limit.
            description: >-
              `{{$labels.namespace}}/{{$labels.persistentvolumeclaim}}`
              (*{{$value|humanizePercentage}}*)
            dashboard: https://grafana.${cluster_domain}/
            runbook: https://d.n3t.uk/runbooks/
          labels:
            ignore: outside-non-work-hours
            severity: warning
            slack: kub3-${cluster}-alerts-infra
            pagerduty: send
            incidentio: send
            team: platform

        - alert: PersistentVolumeClaimCapacityCritical
          expr: |-
            (
              (
                kubelet_volume_stats_available_bytes{
                  job="kubelet",
                  metrics_path="/metrics"
                }
              / kubelet_volume_stats_capacity_bytes{
                  job="kubelet",
                  metrics_path="/metrics"
                }
              ) <= 0.3
              and
              predict_linear(
                kubelet_volume_stats_available_bytes{
                  job="kubelet",
                  metrics_path="/metrics"
                }[3h],
                (2 * 24 * 60 * 60)
              ) <= 0
            )
          for: 30m
          annotations:
            title: >-
              `PersistentVolumeClaim` at Capacity within 2d
            summary: >-
              One or more `PersistentVolumeClaims` on the `{{$externalLabels.cluster}}` Cluster is
              reporting as having *less than 30% of its total avilable capacity free*, and, based
              on current rates of storage, *will fill within the next two days*, which is below
              the *critical* limit.
            description: >-
              `{{$labels.namespace}}/{{$labels.persistentvolumeclaim}}`
              (*{{$value|humanizePercentage}}*)
            dashboard: https://grafana.${cluster_domain}/
            runbook: https://d.n3t.uk/runbooks/
          labels:
            ignore: outside-extended-hours
            severity: critical
            slack: kub3-${cluster}-alerts-infra
            pagerduty: send
            incidentio: create
            team: platform

        - alert: PersistentVolumeErrors
          expr: |-
            kube_persistentvolumeclaim_status_phase{
              phase=~"Pending|Failed"
            } > 0
          for: 2m
          annotations:
            title: >-
              `PersistentVolume` is Pending or Failed
            summary: >-
              One or more `PersistentVolumes` on the `{{$externalLabels.cluster}}` Cluster is
              reporting as being in a `Pending` or `Failed` state and therefore may be preventing
              normal operations of the attached `Pod`.
            description: >-
              `{{$labels.namespace}}/{{$labels.persistentvolume}}` `PersistentVolume`
              (`{{$labels.phase}}` phase)
            dashboard: https://grafana.${cluster_domain}/
            runbook: https://d.n3t.uk/runbooks/
          labels:
            ignore: never
            severity: critical
            slack: kub3-${cluster}-alerts-infra
            pagerduty: send
            incidentio: create
            team: platform

        - alert: PersistentVolumeClaimErrors
          expr: |-
            kube_persistentvolumeclaim_status_phase{
              phase=~"Pending|Lost"
            } > 0
          for: 2m
          annotations:
            title: >-
              `PersistentVolumeClaim` is Pending or Lost
            summary: >-
              One or more `PersistentVolumeClaims` on the `{{$externalLabels.cluster}}` Cluster is
              reporting as being in a `Pending` or `Lost` state and therefore may be preventing
              normal operations of the attached `Pod` or `StatefulSet`.
            description: >-
              `{{$labels.namespace}}/{{$labels.persistentvolumeclaim}}` `PersistentVolumeClaim`
              (`{{$labels.phase}}` phase)
            dashboard: https://grafana.${cluster_domain}/
            runbook: https://d.n3t.uk/runbooks/
          labels:
            ignore: never
            severity: critical
            slack: kub3-${cluster}-alerts-infra
            pagerduty: send
            incidentio: create
            team: platform
